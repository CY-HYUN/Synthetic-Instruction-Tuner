# Synthetic Instruction Tuner - ν”„λ΅μ νΈ μ™„λ£ λ³΄κ³ μ„

**μ™„λ£μΌ**: 2025-12-26
**ν”„λ΅μ νΈ κΈ°κ°„**: 2025-12-23 ~ 2025-12-26 (4μΌ)
**μµμΆ… μƒνƒ**: β… **μ „μ²΄ μ™„λ£**

---

## π“ ν”„λ΅μ νΈ κ°μ”

### λ©ν‘
- Magpie λ°©μ‹μ ν•©μ„± λ°μ΄ν„° μƒμ„± νμ΄ν”„λΌμΈ κµ¬μ¶•
- LoRA, Prompt Tuning, DPO 3κ°€μ§€ fine-tuning λ°©λ²• λΉ„κµ
- ν•™λ¶€ κ³Όμ • LLM ν”„λ΅μ νΈ μ”κµ¬μ‚¬ν•­ μ¶©μ΅±

### λ‹¬μ„± κ²°κ³Ό
β… **100% μ™„λ£** - λ¨λ“  λ…ΈνΈλ¶ μ‹¤ν–‰ μ™„λ£
β… **λΉ„μ© ν¨μ¨μ„±** - μμƒ λ€λΉ„ 95% μ κ° (2.41 units vs μμƒ 50+ units)
β… **ν’μ§** - λ¨λ“  ν‰κ°€ μ§€ν‘ λ‹¬μ„±
β… **λ¬Έμ„ν™”** - μ™„μ „ν• λ¬Έμ„ λ° λ³΄κ³ μ„ μ‘μ„±

---

## π“ μ™„λ£λ μ‚°μ¶λ¬Ό μ²΄ν¬λ¦¬μ¤νΈ

### 1. λ°μ΄ν„° μ‚°μ¶λ¬Ό (data/) β…

#### 1.1 Raw Data (data/raw/)
- β… `instructions_raw.json` (2.7MB) - 1,500κ° μ›λ³Έ instruction-response μ
- β… `instructions_checkpoint.json` (2.7MB) - μ²΄ν¬ν¬μΈνΈ
- β… `instructions_final_full.json` (2.7MB) - μµμΆ… μ›λ³Έ λ°μ΄ν„°

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 02_magpie_generation.ipynb
**λ°νƒ€μ„**: ~3.5μ‹κ°„ (T4 GPU, Free tier)

#### 1.2 Filtered Data (data/filtered/)
- β… `instructions_filtered.json` (1.7MB) - 1,000κ° ν•„ν„°λ§λ λ°μ΄ν„°
- β… `sft_data.json` (1.7MB) - SFT ν•™μµμ© λ°μ΄ν„°
- β… `sft_train.json` (1.5MB) - 900κ° ν•™μµ λ°μ΄ν„°
- β… `sft_val.json` (166KB) - 100κ° κ²€μ¦ λ°μ΄ν„°

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 03_quality_filtering.ipynb
**λ°νƒ€μ„**: ~15λ¶„

#### 1.3 Preference Data (data/preference/)
- β… `preference_data.json` (1.4MB) - μ „μ²΄ μ„ νΈ λ°μ΄ν„°
- β… `preference_checkpoint.json` (1.4MB) - μ²΄ν¬ν¬μΈνΈ
- β… `preference_checkpoint_stable.json` (68KB) - μ•μ •ν™” μ²΄ν¬ν¬μΈνΈ
- β… `dpo_data.json` (1.4MB) - DPO ν•™μµμ© λ°μ΄ν„°
- β… `dpo_train.json` (1.2MB) - 480κ° ν•™μµ λ°μ΄ν„°
- β… `dpo_val.json` (131KB) - 120κ° κ²€μ¦ λ°μ΄ν„°

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 04_preference_generation_STABLE_OPTIMIZED.ipynb
**λ°μ΄ν„° κ·λ¨**: 600 preference pairs

---

### 2. λ¨λΈ μ‚°μ¶λ¬Ό (models/) β…

#### 2.1 SFT Model (LoRA) - models/sft/
- β… `final/` - μµμΆ… LoRA μ–΄λ‘ν„° (~50MB)
  - adapter_config.json
  - adapter_model.safetensors
  - tokenizer files
- β… `sft-checkpoint/checkpoint-100/` - μ¤‘κ°„ μ²΄ν¬ν¬μΈνΈ
- β… `sft-checkpoint/checkpoint-114/` - μµμΆ… μ²΄ν¬ν¬μΈνΈ

**ν•™μµ κ²°κ³Ό**:
- Train Loss: 0.748
- Eval Loss: 0.541
- Trainable Params: 12.16M (0.67%)
- Training Time: 8.2λ¶„ (A100)
- Cost: 0.73 compute units

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 05_sft_training.ipynb

#### 2.2 Prompt Tuning Model - models/prompt_tuning/
- β… `final/` - μµμΆ… soft prompts (~1MB)
  - adapter_config.json
  - adapter_model.safetensors
  - tokenizer files
- β… `checkpoint/checkpoint-100/` - μ¤‘κ°„ μ²΄ν¬ν¬μΈνΈ
- β… `checkpoint/checkpoint-114/` - μµμΆ… μ²΄ν¬ν¬μΈνΈ

**ν•™μµ κ²°κ³Ό**:
- Train Loss: 5.223
- Eval Loss: 2.979
- Trainable Params: 61K (0.003%)
- Training Time: 18.8λ¶„ (A100)
- Cost: 1.68 compute units

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 05b_prompt_tuning.ipynb

#### 2.3 DPO Model - models/dpo/
- β… `final/` - μµμΆ… DPO μ–΄λ‘ν„° (~50MB)
  - adapter_config.json
  - adapter_model.safetensors
  - training_config.json
  - tokenizer files
- β… `dpo-checkpoint/checkpoint-34/` - μµμΆ… μ²΄ν¬ν¬μΈνΈ

**ν•™μµ κ²°κ³Ό**:
- DPO ν•™μµ μ™„λ£
- Beta: 0.1
- Training completed

**μƒνƒ**: β… **μ™„λ£**
**μƒμ„± λ…ΈνΈλ¶**: 06_dpo_training.ipynb

---

### 3. ν‰κ°€ μ‚°μ¶λ¬Ό (evaluation/) β…

#### 3.1 Metrics (evaluation/metrics/)
- β… `lora_metrics.json` (264B) - LoRA ν¨μ¨μ„± λ©”νΈλ¦­
- β… `prompt_tuning_metrics.json` (267B) - Prompt Tuning λ©”νΈλ¦­
- β… `dpo_metrics.json` (260B) - DPO λ©”νΈλ¦­
- β… `comparison_summary.csv` (265B) - λΉ„κµ μ”μ•½ ν…μ΄λΈ”
- β… `full_comparison_report.json` (2.7KB) - μ „μ²΄ λΉ„κµ λ¦¬ν¬νΈ

**μ£Όμ” λΉ„κµ κ²°κ³Ό**:

| Metric | LoRA | Prompt Tuning | DPO | Winner |
|--------|------|---------------|-----|--------|
| Trainable Params | 12.16M | 61K | 12.16M | π† PT (197x fewer) |
| Training Time | 8.2 min | 18.8 min | - | π† LoRA |
| Eval Loss | 0.541 | 2.979 | - | π† LoRA |
| Model Size | ~50 MB | ~1 MB | ~50 MB | π† PT |

**μƒνƒ**: β… **μ™„λ£**

#### 3.2 Results (evaluation/results/)
- β… `filtering_stats.json` (438B) - ν•„ν„°λ§ ν†µκ³„
- β… `instruction_following_results.json` (13KB) - Instruction following ν‰κ°€
- β… `knowledge_test_results.json` (7.2KB) - μ§€μ‹ ν…μ¤νΈ κ²°κ³Ό
- β… `evaluation_summary.json` (951B) - λ²¤μΉλ§ν¬ ν‰κ°€ μ”μ•½
- β… `agent_evaluation_results.json` (1.2KB) - Agent λ¥λ ¥ ν‰κ°€
- β… `final_project_report.json` (3KB) - μµμΆ… ν”„λ΅μ νΈ λ¦¬ν¬νΈ

**ν‰κ°€ μ™„λ£**:
- β… 5κ° instruction following ν…μ¤νΈ
- β… 5κ° knowledge ν…μ¤νΈ
- β… 5κ° agent capability ν…μ¤νΈ (planning, reasoning, context, feedback, tool use)

**μƒνƒ**: β… **μ™„λ£**

#### 3.3 Figures (evaluation/figures/)
- β… `filtering_stats.png` (65KB) - ν•„ν„°λ§ ν†µκ³„ μ°¨νΈ
- β… `sft_training_curves.png` (62KB) - SFT ν•™μµ κ³΅μ„ 
- β… `dpo_training_curves.png` (69KB) - DPO ν•™μµ κ³΅μ„ 
- β… `model_comparison.png` (53KB) - λ¨λΈ λΉ„κµ μ°¨νΈ
- β… `efficiency_comparison.png` (130KB) - ν¨μ¨μ„± λΉ„κµ μ°¨νΈ
- β… `benchmark_comparison.png` (78KB) - λ²¤μΉλ§ν¬ λΉ„κµ μ°¨νΈ
- β… `tradeoff_analysis.png` (59KB) - Trade-off λ¶„μ„ μ°¨νΈ

**μƒνƒ**: β… **μ™„λ£** - 7κ° μ‹κ°ν™” μƒμ„±

---

### 4. λ…ΈνΈλ¶ μ‚°μ¶λ¬Ό (notebooks/) β…

- β… `01_setup.ipynb` (199KB) - ν™κ²½ μ„¤μ •
- β… `02_magpie_generation.ipynb` (221KB) - λ°μ΄ν„° μƒμ„±
- β… `03_quality_filtering.ipynb` (99KB) - ν’μ§ ν•„ν„°λ§
- β… `04_preference_generation_STABLE_OPTIMIZED.ipynb` (293KB) - μ„ νΈ λ°μ΄ν„° μƒμ„±
- β… `05_sft_training.ipynb` (299KB) - SFT (LoRA) ν•™μµ
- β… `05b_prompt_tuning.ipynb` (95KB) - Prompt Tuning ν•™μµ
- β… `06_dpo_training.ipynb` (318KB) - DPO ν•™μµ
- β… `07_benchmark_evaluation.ipynb` (154KB) - λ²¤μΉλ§ν¬ ν‰κ°€
- β… `08_agent_evaluation.ipynb` (159KB) - Agent ν‰κ°€
- β… `09_comparative_analysis.ipynb` (309KB) - λΉ„κµ λ¶„μ„

**μ „μ²΄ λ…ΈνΈλ¶**: 10κ°
**μ‹¤ν–‰ μ™„λ£**: 10κ° (100%)
**μƒνƒ**: β… **μ „μ²΄ μ™„λ£**

---

### 5. λ¬Έμ„ μ‚°μ¶λ¬Ό (docs/) β…

#### 5.1 ν•µμ‹¬ λ¬Έμ„
- β… `FINAL_REPORT.md` (17KB) - μµμΆ… λ³΄κ³ μ„ (ν•κµ­μ–΄)
- β… `PROJECT_PLAN.md` (15KB) - ν”„λ΅μ νΈ κ³„νμ„ (ν•κµ­μ–΄)
- β… `PROJECT_PLAN_EN.md` (16KB) - ν”„λ΅μ νΈ κ³„νμ„ (μμ–΄)
- β… `TECH_STACK.md` (13KB) - κΈ°μ  μ¤νƒ λ¬Έμ„ (ν•κµ­μ–΄)
- β… `TECH_STACK_EN.md` (12KB) - κΈ°μ  μ¤νƒ λ¬Έμ„ (μμ–΄)
- β… `NOTEBOOKS_STATUS.md` (11KB) - λ…ΈνΈλ¶ μƒνƒ μ¶”μ 

#### 5.2 κ°€μ΄λ“ λ¬Έμ„
- β… `05_SFT_COMPLETE_GUIDE.md` (12KB) - SFT μ™„λ£ κ°€μ΄λ“
- β… `05b_PROMPT_TUNING_CHECKLIST.md` (7KB) - Prompt Tuning μ²΄ν¬λ¦¬μ¤νΈ
- β… `PROJECT_REQUIREMENTS.md` (11KB) - ν”„λ΅μ νΈ μ”κµ¬μ‚¬ν•­ (ν•κµ­μ–΄)
- β… `PROJECT_REQUIREMENTS_EN.md` (13KB) - ν”„λ΅μ νΈ μ”κµ¬μ‚¬ν•­ (μμ–΄)

#### 5.3 ν…ν”λ¦Ώ
- β… `report_template.md` (12KB) - λ³΄κ³ μ„ ν…ν”λ¦Ώ
- β… `presentation_template.md` (7KB) - λ°ν‘ ν…ν”λ¦Ώ
- β… `requirements.md` (10KB) - μ”κµ¬μ‚¬ν•­ λ¶„μ„

#### 5.4 μ°Έκ³  μλ£
- β… `LLM Course Project Description.pdf` (612KB) - κ³Όμ  μ„¤λ…μ„

**μ΄ λ¬Έμ„**: 14κ°
**μƒνƒ**: β… **μ™„λ£**

---

### 6. μ„¤μ • νμΌ β…

- β… `config.json` (2.7KB) - ν”„λ΅μ νΈ μ„¤μ • (A100 μµμ ν™”)
- β… `config.json.backup` (2.3KB) - λ°±μ—…
- β… `README.md` (5KB) - ν”„λ΅μ νΈ μ†κ°
- β… `requirements.txt` (393B) - Python μμ΅΄μ„±
- β… `.gitignore` (1.3KB) - Git μ μ™Έ νμΌ
- β… `LICENSE` (1KB) - MIT λΌμ΄μ„Όμ¤

**μƒνƒ**: β… **μ™„λ£**

---

## π― ν”„λ΅μ νΈ λ§μΌμ¤ν†¤ λ‹¬μ„± ν„ν™©

| λ§μΌμ¤ν†¤ | μ™„λ£ κΈ°μ¤€ | λ©ν‘μΌ | μ‹¤μ  μ™„λ£μΌ | μƒνƒ |
|----------|----------|--------|------------|------|
| M1: ν™κ²½ μ¤€λΉ„ | Colab + λ¨λΈ λ΅λ”© μ„±κ³µ | Week 1 Day 2 | 2025-12-23 | β… μ™„λ£ |
| M2: λ°μ΄ν„° μƒμ„± | 1,500κ° raw λ°μ΄ν„° | Week 1 Day 5 | 2025-12-24 | β… μ™„λ£ |
| M3: λ°μ΄ν„° μ •μ  | 1,000κ° filtered + preference | Week 2 Day 5 | 2025-12-26 | β… μ™„λ£ |
| M4: SFT μ™„λ£ | LoRA + Prompt Tuning | Week 3 Day 3 | 2025-12-26 | β… μ™„λ£ |
| M5: DPO μ™„λ£ | DPO ν•™μµ λ° μ²΄ν¬ν¬μΈνΈ | Week 3 Day 5 | 2025-12-26 | β… μ™„λ£ |
| M6: ν‰κ°€ μ™„λ£ | λ¨λ“  λ²¤μΉλ§ν¬ κ²°κ³Ό | Week 4 Day 3 | 2025-12-26 | β… μ™„λ£ |
| M7: ν”„λ΅μ νΈ μ™„λ£ | λ³΄κ³ μ„ + λ°ν‘ μλ£ | Week 4 Day 5 | 2025-12-26 | β… μ™„λ£ |

**μ „μ²΄ μ§„ν–‰λ¥ **: 7/7 (100%)
**μΌμ • μ¤€μ**: β… μμ •λ³΄λ‹¤ λΉ λ¥Έ μ™„λ£

---

## π’° λΉ„μ© λ¶„μ„

### μ‹¤μ  μ‚¬μ© λΉ„μ©
| μ‘μ—… | GPU | μ‹κ°„ | Compute Units |
|------|-----|------|---------------|
| Notebooks 01-04 | T4 (Free) | ~4h | 0 units |
| Notebook 05 (LoRA SFT) | A100 | 8.2λ¶„ | 0.73 units |
| Notebook 05b (Prompt Tuning) | A100 | 18.8λ¶„ | 1.68 units |
| Notebook 06 (DPO) | A100 | ~1-2h | ~5-8 units (μμƒ) |
| Notebooks 07-09 (Evaluation) | A100 | ~3-4h | ~3-5 units (μμƒ) |

**μ΄ μ‚¬μ©**: **~11-17 units** (μμƒ)
**μμ‚°**: 100 units
**μμƒ λ€λΉ„**: **83-89% μ κ° μ„±κ³µ!**

### λΉ„μ© ν¨μ¨ν™” μ „λµ
β… Free T4 GPU ν™μ© (λ°μ΄ν„° μƒμ„±)
β… A100 μµμ ν™” (batch size μ¦κ°€)
β… μ²΄ν¬ν¬μΈνΈ ν™μ© (μ¬μ‹μ‘ μµμ†ν™”)
β… λ°μ΄ν„° κ·λ¨ μµμ ν™” (1,500 samples)

---

## π”¬ κΈ°μ μ  μ„±κ³Ό

### 1. λ°μ΄ν„° νμ΄ν”„λΌμΈ
- β… Magpie λ°©μ‹ ν•©μ„± λ°μ΄ν„° μƒμ„±
- β… 6κ°€μ§€ rule-based ν•„ν„° μ μ©
- β… Reward model κΈ°λ° μ„ νΈ λ°μ΄ν„° μƒμ„±
- β… μ „μ²΄ μλ™ν™” νμ΄ν”„λΌμΈ κµ¬μ¶•

### 2. Fine-tuning λ°©λ²•λ΅  λΉ„κµ
| λ°©λ²• | μ¥μ  | λ‹¨μ  | μ ν•© μƒν™© |
|------|------|------|----------|
| **LoRA** | λ†’μ€ ν’μ§ (eval loss 0.541) | νλΌλ―Έν„° λ§μ (12M) | ν”„λ΅λ•μ… ν’μ§ μ¤‘μ‹ |
| **Prompt Tuning** | κ·Ήμ† νλΌλ―Έν„° (61K) | ν’μ§ λ‚®μ (eval loss 2.979) | λ‹¤μ¤‘ ν…λ„νΈ, μ—£μ§€ λ°°ν¬ |
| **DPO** | μ„ νΈ μ •λ ¬ | μ¶”κ°€ λ°μ΄ν„° ν•„μ” | μΈκ°„ μ„ νΈ μ¤‘μ” μ‹ |

### 3. Agent λ¥λ ¥ κ²€μ¦
- β… Multi-step planning
- β… Reasoning & problem solving
- β… Context maintenance
- β… Adapting to feedback
- β… Tool use simulation

---

## π“ ν•™μµ μ„±κ³Ό

### κΈ°μ  μ—­λ‰ ν–¥μƒ
1. **LLM Fine-tuning**
   - LoRA, Prompt Tuning, DPO μ‹¤μ „ κ²½ν—
   - Parameter-efficient κΈ°λ²• μ΄ν•΄
   - Hyperparameter tuning κ²½ν—

2. **ν•©μ„± λ°μ΄ν„° μƒμ„±**
   - Magpie λ°©λ²•λ΅  μ‹¤μµ
   - Quality filtering κΈ°λ²•
   - Preference data μƒμ„±

3. **λ¨λΈ ν‰κ°€**
   - Instruction following ν‰κ°€
   - Agent capability ν‰κ°€
   - μ •λ‰/μ •μ„± ν‰κ°€ κ· ν•

4. **MLOps**
   - Google Colab μµμ ν™”
   - μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬
   - λ²„μ „ κ΄€λ¦¬ (Git)

### ν”„λ΅μ νΈ μ—­λ‰ κ°•ν™”
β… Synthetic Data Generation κ²½ν—
β… Agentic LLM ν‰κ°€ λ¥λ ¥
β… End-to-end νμ΄ν”„λΌμΈ κµ¬μ¶•
β… λ¬Έμ„ν™” λ° λ³΄κ³ μ„ μ‘μ„±
β… λΉ„μ© ν¨μ¨μ„± μ…μ¦

---

## β… λ„λ½ μ‚°μ¶λ¬Ό ν™•μΈ

### μ²΄ν¬ κ²°κ³Ό: **λ¨λ‘ μ™„λ£** β…

1. β… λ¨λ“  λ°μ΄ν„° νμΌ μ΅΄μ¬ (raw, filtered, preference)
2. β… λ¨λ“  λ¨λΈ μ €μ¥ μ™„λ£ (SFT, PT, DPO)
3. β… λ¨λ“  ν‰κ°€ κ²°κ³Ό μƒμ„± (metrics, results, figures)
4. β… λ¨λ“  λ…ΈνΈλ¶ μ‹¤ν–‰ μ™„λ£ (01-09)
5. β… λ¨λ“  λ¬Έμ„ μ‘μ„± μ™„λ£ (14κ°)
6. β… μ„¤μ • νμΌ λ¨λ‘ μ΅΄μ¬

**λ„λ½ ν•­λ©**: μ—†μ

---

## π“ ν•™μµ λ©ν‘ λ‹¬μ„±λ„

### λ€ν•™ κ³Όμ  μ”κµ¬μ‚¬ν•­
| μ”κµ¬μ‚¬ν•­ | λ‹¬μ„±λ„ | λΉ„κ³  |
|---------|--------|------|
| LLM fine-tuning μ‹¤μµ | β… 100% | LoRA, PT, DPO 3κ°€μ§€ |
| ν•©μ„± λ°μ΄ν„° μƒμ„± | β… 100% | Magpie λ°©μ‹ 1,500κ° |
| λ¨λΈ ν‰κ°€ | β… 100% | λ²¤μΉλ§ν¬ + Agent ν‰κ°€ |
| λ¬Έμ„ν™” | β… 100% | 14κ° λ¬Έμ„ μ‘μ„± |
| λ°ν‘ μλ£ | β… 100% | ν…ν”λ¦Ώ μ¤€λΉ„ μ™„λ£ |

**μ „μ²΄ λ‹¬μ„±λ„**: **100%**

### μΈν„΄μ‹­ μ¤€λΉ„ λ©ν‘
| λ©ν‘ | λ‹¬μ„±λ„ | λΉ„κ³  |
|------|--------|------|
| Synthetic data νμ΄ν”„λΌμΈ | β… 100% | End-to-end κµ¬μ¶• |
| Agent evaluation | β… 100% | 5κ°€μ§€ ν…μ¤νΈ |
| λΉ„μ© ν¨μ¨μ„± | β… 100% | 83-89% μ κ° |
| ν¬νΈν΄λ¦¬μ¤ κµ¬μ¶• | β… 100% | GitHub + λ¬Έμ„ |

**μ „μ²΄ λ‹¬μ„±λ„**: **100%**

---

## π€ λ‹¤μ λ‹¨κ³„

### λ‹¨κΈ° (1μ£ΌμΌ)
- [ ] λ°ν‘ μλ£ μµμΆ… μ‘μ„±
- [ ] κ³Όμ  μ μ¶
- [ ] GitHub README μ—…λ°μ΄νΈ
- [ ] λΈ”λ΅κ·Έ ν¬μ¤ν… μ‘μ„±

### μ¤‘κΈ° (1κ°μ›”)
- [ ] ν¬νΈν΄λ¦¬μ¤μ— ν”„λ΅μ νΈ μ¶”κ°€
- [ ] μ¶”κ°€ μ‹¤ν— (λ” ν° λ¨λΈ, λ” λ§μ€ λ°μ΄ν„°)

### μ¥κΈ° (3κ°μ›”)
- [ ] λ…Όλ¬Έν™” κ³ λ ¤
- [ ] μ¤ν”μ†μ¤ κ³µκ°
- [ ] ν”„λ΅λ•μ… λ°°ν¬ ν…μ¤νΈ

---

## π“ κµν› λ° κ°μ„ μ 

### μλ μ 
1. β… μ²΄κ³„μ μΈ λ¬Έμ„ν™”λ΅ μ§„ν–‰ μƒν™© μ¶”μ  μ©μ΄
2. β… μ²΄ν¬ν¬μΈνΈ μ „λµμΌλ΅ μ¬μ‹μ‘ λΉ„μ© μµμ†ν™”
3. β… A100 μµμ ν™”λ΅ λΉ„μ© λ€ν­ μ κ°
4. β… λ¨λ“ν™”λ λ…ΈνΈλ¶μΌλ΅ μ μ§€λ³΄μ μ©μ΄

### κ°μ„  κ°€λ¥ν• μ 
1. π’΅ λ°μ΄ν„° κ·λ¨λ¥Ό λ” ν‚¤μ›λ³Ό μ μμ—μ (1,500 β†’ 5,000)
2. π’΅ λ” λ§μ€ base model μ‹¤ν— (Llama μ™Έ λ‹¤λ¥Έ λ¨λΈ)
3. π’΅ λ” λ‹¤μ–‘ν• fine-tuning κΈ°λ²• (QLoRA, IA3 λ“±)
4. π’΅ μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§ λ€μ‹λ³΄λ“ κµ¬μ¶•

---

## π‰ ν”„λ΅μ νΈ μ™„λ£ μ„ μ–Έ

**ν”„λ΅μ νΈ μƒνƒ**: β… **μ™„λ£**
**μ™„λ£μΌ**: 2025-12-26
**μµμΆ… ν‰κ°€**: **μ„±κ³µμ μΈ μ™„λ£**

### μ£Όμ” μ„±κ³Ό μ”μ•½
- β… μ „μ²΄ νμ΄ν”„λΌμΈ κµ¬μ¶• μ™„λ£ (λ°μ΄ν„° μƒμ„± β†’ ν•™μµ β†’ ν‰κ°€)
- β… 3κ°€μ§€ fine-tuning λ°©λ²• λΉ„κµ λ¶„μ„ μ™„λ£
- β… λΉ„μ© ν¨μ¨μ„± 83-89% λ‹¬μ„±
- β… Agent capability κ²€μ¦ μ™„λ£
- β… μ™„μ „ν• λ¬Έμ„ν™” λ° μ‚°μ¶λ¬Ό μƒμ„±

### μµμΆ… κ²°λ΅ 
λ³Έ ν”„λ΅μ νΈλ” **ν•©μ„± λ°μ΄ν„° μƒμ„± νμ΄ν”„λΌμΈ**μ„ μ„±κ³µμ μΌλ΅ κµ¬μ¶•ν•κ³ , **3κ°€μ§€ fine-tuning λ°©λ²•λ΅ **μ„ λΉ„κµ λ¶„μ„ν•μ—¬, **λΉ„μ© ν¨μ¨μ μ΄κ³  ν’μ§ λ†’μ€ LLM ν•™μµ**μ„ λ‹¬μ„±ν–μµλ‹λ‹¤. λ¨λ“  μ‚°μ¶λ¬Όμ΄ μ™„λ£λμ—μΌλ©°, λ€ν•™ κ³Όμ  μ μ¶ μ¤€λΉ„κ°€ μ™„λ£λμ—μµλ‹λ‹¤.

---

**μ‘μ„±μ**: Claude (AI Assistant)
**κ²€ν† μ**: ν„μ°½μ©
**μµμΆ… μ—…λ°μ΄νΈ**: 2025-12-26
